{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек"
      ],
      "metadata": {
        "id": "gAIbGHbzaG9L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "uQeyIyoJpMs8"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "from reach import Reach\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from tqdm import tqdm\n",
        "from collections import Counter, defaultdict\n",
        "import itertools\n",
        "from spacy.symbols import NOUN, PROPN, PUNCT, SYM, ADP, DET, ADJ\n",
        "\n",
        "nlp = spacy.load(\"ru_core_news_lg\")\n",
        "stopwords_ru = stopwords.words(\"russian\")\n",
        "tqdm.pandas(desc=\"progress-bar\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#! pip3 install reach\n",
        "#! python3 -m spacy download ru_core_news_lg\n",
        "# nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3cRRKV7A--F",
        "outputId": "8cd7d0dd-8c8d-4f44-83a3-7fc8c1e467b5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка датасетов"
      ],
      "metadata": {
        "id": "sCJflg5laVFG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "WMiXkVKv_s6-"
      },
      "outputs": [],
      "source": [
        "# для word2vec\n",
        "\n",
        "df_train = pd.read_excel('tmp.xlsx')\n",
        "\n",
        "df_train = df_train[~df_train['text'].isnull()]\n",
        "df_train = df_train[df_train['text'] != 'string']\n",
        "df_train = df_train.head(5000)\n",
        "\n",
        "corpus = [x.lower().replace('...', '.').replace('.', '. ').replace(' .', '. ').strip().split() for x in df_train['text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VdGvhtLid-ep"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('review.xlsx')\n",
        "df = df.drop('Unnamed: 0', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.head(5000)"
      ],
      "metadata": {
        "id": "TiYm6HVIjGRU"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec"
      ],
      "metadata": {
        "id": "cExBMfjTc0hk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "QI-4Xf0KdoYL"
      },
      "outputs": [],
      "source": [
        "f = Word2Vec(corpus,\n",
        "             sg=0,\n",
        "             negative=5,\n",
        "             window=10,\n",
        "             size=200,\n",
        "             min_count=2,\n",
        "             workers=10\n",
        "            )\n",
        "f.wv.save_word2vec_format(\"my_word_vectors.vec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "HDpNucGleDjr"
      },
      "outputs": [],
      "source": [
        " r = Reach.load(\"my_word_vectors.vec\", unk_word=\"<UNK>\")\n",
        " r.vectors[r.items[\"<UNK>\"]] = r.vectors.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кандидаты в аспектные термины"
      ],
      "metadata": {
        "id": "5bqS6Qo8dlQo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YCYuHX1IezNF"
      },
      "outputs": [],
      "source": [
        "def get_noun_phrases(texts):\n",
        "    \n",
        "    features_dict = Counter()\n",
        "    a = []\n",
        "    \n",
        "    for item in tqdm(texts):\n",
        "        text_nlp = nlp(item)\n",
        "        a = [str(word) for word in text_nlp if word.tag_ in('NOUN', 'PROPN')] + a\n",
        "    features_dict.update(a)\n",
        "    return features_dict\n",
        "\n",
        "def sent_token(text):\n",
        "    \"\"\"\n",
        "    Токенизация по предложениям\n",
        "    \"\"\"\n",
        "    text = str(text).lower()\n",
        "    text = text.replace('...', '.').replace('.', '. ')\n",
        "    return [nlp(x, disable=[\"ner\"]) for x in nltk.sent_tokenize(text)]\n",
        "\n",
        "\n",
        "def process_sent(text, remove_stopwords=False, min_token_length=3):\n",
        "    \"\"\" \n",
        "    Apply text preprocessing steps \n",
        "    \"\"\"\n",
        "    if remove_stopwords:\n",
        "        return \" \".join([token.lemma_.lower() for token in text if not token.is_stop \n",
        "                         and len(token.text) >= min_token_length])\n",
        "    else:\n",
        "        return \" \".join([token.lemma_.lower() for token in text if len(token.text) >= min_token_length])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd11Dg58gnMG",
        "outputId": "707cbb33-67ca-4f38-aecc-7ea399f2b0b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "progress-bar: 100%|██████████| 284/284 [00:36<00:00,  7.83it/s]\n",
            "progress-bar: 100%|██████████| 3466/3466 [00:00<00:00, 51550.54it/s]\n",
            "100%|██████████| 3466/3466 [00:40<00:00, 85.31it/s]\n"
          ]
        }
      ],
      "source": [
        "df[\"sentences\"] = df[\"review\"].progress_map(lambda x: sent_token(x))\n",
        "df = df.explode('sentences')\n",
        "df.index = np.arange(0, len(df))\n",
        "df['clean_sent'] = df['sentences'].progress_map(lambda x: process_sent(x))\n",
        "features_dict = get_noun_phrases(list(df['clean_sent']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"sentences\"] = df_train[\"text\"].progress_map(lambda x: sent_token(x))\n",
        "df_train = df_train.explode('sentences')\n",
        "df_train.index = np.arange(0, len(df_train))\n",
        "df_train['clean_sent'] = df_train['sentences'].progress_map(lambda x: process_sent(x))\n",
        "features_dict = get_noun_phrases(list(df_train['clean_sent']))\n",
        "\n",
        "aspects = [[k] for k, v in features_dict.most_common(200)]\n",
        "aspect_vecs = [x.mean(0) for x in r.transform(aspects, remove_oov=False)]\n",
        "aspect_vecs = np.stack(aspect_vecs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-z5RONWioE5",
        "outputId": "249301e7-a535-4eb2-be96-218f8309f6c7"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "progress-bar: 100%|██████████| 5000/5000 [02:13<00:00, 37.36it/s] \n",
            "progress-bar: 100%|██████████| 15722/15722 [00:00<00:00, 70565.22it/s]\n",
            "100%|██████████| 15722/15722 [02:53<00:00, 90.67it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "gkBLITZzzuBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6337cd55-a97c-420e-9247-7cde8ff190d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3466/3466 [00:33<00:00, 103.07it/s]\n"
          ]
        }
      ],
      "source": [
        "features_dict = get_noun_phrases(list(df['sentences']))\n",
        "aspects = [[k] for k, v in features_dict.most_common(200)]\n",
        "aspect_vecs = [x.mean(0) for x in r.transform(aspects, remove_oov=False)]\n",
        "aspect_vecs = np.stack(aspect_vecs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_dict.most_common(200)[0:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2_O2LzfiJzn",
        "outputId": "1b067d8e-0154-4a5a-ca2d-d611cf115ae9"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('бургер', 1764),\n",
              " ('место', 1093),\n",
              " ('обслуживание', 700),\n",
              " ('кухня', 653),\n",
              " ('еда', 617),\n",
              " ('ресторан', 611),\n",
              " ('заведение', 577),\n",
              " ('цена', 549),\n",
              " ('блюдо', 473),\n",
              " ('персонал', 427),\n",
              " ('официант', 411),\n",
              " ('меню', 396),\n",
              " ('заказ', 374),\n",
              " ('раз', 362),\n",
              " ('атмосфера', 282),\n",
              " ('вкус', 265),\n",
              " ('музыка', 251),\n",
              " ('мясо', 245),\n",
              " ('очередь', 245),\n",
              " ('человек', 227),\n",
              " ('качество', 225),\n",
              " ('минута', 222),\n",
              " ('интерьер', 221),\n",
              " ('стол', 213),\n",
              " ('перчатка', 210),\n",
              " ('вечер', 189),\n",
              " ('время', 185),\n",
              " ('спасибо', 182),\n",
              " ('народ', 180),\n",
              " ('котлета', 179)]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention"
      ],
      "metadata": {
        "id": "kDjDmP5Keunq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import rbf_kernel, euclidean_distances\n",
        "\n",
        "def rbf_attention(vec, memory, gamma=0.1, **kwargs):\n",
        "    \"\"\"\n",
        "    Single-head attention using RBF kernel.\n",
        "    Parameters\n",
        "    ----------\n",
        "    vec : np.array\n",
        "        an (N, D)-shaped array, representing the tokens of an instance.\n",
        "    memory : np.array\n",
        "        an (M, D)-shaped array, representing the memory items\n",
        "    gamma : float\n",
        "        the gamma of the RBF kernel.\n",
        "    Returns\n",
        "    -------\n",
        "    attention : np.array\n",
        "        A (1, N)-shaped array, representing a single-headed attention mechanism\n",
        "    \"\"\"\n",
        "    z = rbf_kernel(vec, memory, gamma)\n",
        "    s = z.sum()\n",
        "    if s == 0:\n",
        "        # If s happens to be 0, back off to uniform\n",
        "        return np.ones((1, len(vec))) / len(vec)\n",
        "    return (z.sum(1) / s)[None, :]\n",
        "\n",
        "\n",
        "def softmax(x, axis=1):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x, axis, keepdims=True))\n",
        "    s = e_x.sum(axis=axis, keepdims=True)\n",
        "    return e_x / s\n",
        "\n",
        "\n",
        "def attention(vec, memory, **kwargs):\n",
        "    \"\"\"\n",
        "    Standard multi-head attention mechanism.\n",
        "    Parameters\n",
        "    ----------\n",
        "    vec : np.array\n",
        "        an (N, D)-shaped array, representing the tokens of an instance.\n",
        "    memory : np.array\n",
        "        an (M, D)-shaped array, representing the memory items\n",
        "    Returns\n",
        "    -------\n",
        "    attention : np.array\n",
        "        A (M, N)-shaped array, representing the attention over all memories.\n",
        "    \"\"\"\n",
        "    z = memory.dot(vec.T)\n",
        "    return softmax(z)\n",
        "\n",
        "def normalize(x):\n",
        "    \"\"\"Normalize a vector while controlling for zero vectors.\"\"\"\n",
        "    x = np.copy(x)\n",
        "    if np.ndim(x) == 1:\n",
        "        norm = np.linalg.norm(x)\n",
        "        if norm == 0:\n",
        "            return x\n",
        "        return x / np.linalg.norm(x)\n",
        "    norm = np.linalg.norm(x, axis=-1)\n",
        "    mask = norm > 0\n",
        "    x[mask] /= norm[mask][:, None]\n",
        "    return x"
      ],
      "metadata": {
        "id": "vvj9ws8_FDdH"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "vGXVGd5a2Q3A"
      },
      "outputs": [],
      "source": [
        "instances = [str(x).strip().split() for x in df['sentences']]\n",
        "t = r.transform(instances, remove_oov=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "g8xcgVBB892O"
      },
      "outputs": [],
      "source": [
        "label_vecs = normalize(r.vectorize(['еда', 'обслуживание', 'нет']))\n",
        "assert all([x in r.items for x in ['еда', 'обслуживание']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "QZuHgzpQ3NRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40edd2ee-5831-4add-e710-99d002c581ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3466\n",
            "(1, 8)\n",
            "(1, 200)\n",
            "[[-0.01693357  0.05593684 -0.00727988]] [-0.01693357  0.05593684 -0.00727988]\n",
            "[array([-0.01693357,  0.05593684, -0.00727988])]\n"
          ]
        }
      ],
      "source": [
        "out = []\n",
        "print(len(t))\n",
        "for vec in t:\n",
        "    att = rbf_attention(vec, aspect_vecs)\n",
        "    print(att.shape)\n",
        "    # Att = (n_heads, n_words)\n",
        "    z = att.dot(vec)\n",
        "    print(z.shape)\n",
        "    # z = (n_heads, n_dim)\n",
        "    x = normalize(z).dot(label_vecs.T)\n",
        "    # x = (n_heads, n_labels)\n",
        "    print(x, x.sum(0))\n",
        "    out.append(x.sum(0))\n",
        "    print(out)\n",
        "    break\n",
        "\n",
        "p = np.stack(out)\n",
        "pred = p.argmax(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "KShFdkL1-_C_"
      },
      "outputs": [],
      "source": [
        "instances_a = [y for x in instances for y in x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9huXnxtu_Usb",
        "outputId": "3e8d89f2-9eb6-4f88-eb1f-dc70ff516933"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, ['день', '8-го', 'марта', 'прошёл,', 'можно', 'и', 'итоги', 'подвести.'])]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "list(zip(pred, instances))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPn3CrGe99LY"
      },
      "outputs": [],
      "source": [
        "p = list(np.stack(out).argmax(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_ws7smY9hDg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}